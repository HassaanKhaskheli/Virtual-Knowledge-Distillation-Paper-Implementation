# Virtual Knowledge Distillation via Conditional GAN

This repository contains the implementation of the research paper "A Virtual Knowledge Distillation via Conditional GAN" by Sihwan Kim, Big Data & AI Laboratory, Hana Institute of Technology. The implementation uses a Conditional GAN (cGAN) framework to facilitate knowledge transfer between a large teacher model and a smaller student model, enabling efficient deployment of deep learning models without compromising on accuracy.

---

## Overview

### Paper Abstract
The paper proposes a novel knowledge distillation framework using Conditional GANs, which bridges the gap between the teacher and student models by synthesizing feature representations. This approach enables the student model to learn more effectively from the teacher without directly accessing the original dataset.

### Key Features
- Conditional GAN-based knowledge distillation.
- Facilitates efficient training for smaller student models.
- Reduces dependency on large datasets by synthesizing feature representations.
- Applicable to various domains including image classification and object detection.

---

## Repository Structure

```
├── vkd.ipynb            # Core implementation for Virtual Knowledge Distillation
├── README.md            # Documentation for the repository
```

### Important Note
- **Generator, Teacher, and Student Models:** The model files (.pth) are NOT included in this repository due to size constraints. However, the complete code to train these models is provided in the `vkd.ipynb` file.

---

## Getting Started

### Prerequisites
To run the code in this repository, ensure you have the following installed:

- Python 3.8+
- Jupyter Notebook or Google Colab
- Key Libraries:
  - PyTorch
  - torchvision
  - numpy
  - matplotlib

Install the required libraries by running:

```bash
# pip install torch torchvision matplotlib numpy
```

### Running the Notebook
1. Open the `vkd.ipynb` file in Jupyter Notebook or Google Colab.
2. Follow the cells sequentially to:
   - Train the teacher model
   - Train the generator and discriminator models.
   - Define the Conditional GAN architecture.
   - Perform knowledge distillation using the trained teacher model.
   - Train the student model with synthesized feature representations.

### Outputs
The notebook generates:
- Training logs for the generator, discriminator, teacher, and student models.
- Visualization of synthesized feature representations.
- Evaluation metrics (accuracy) for the student model.

---

## Dataset
This implementation supports multiple datasets, and the specific dataset to be used can be specified in the notebook. Examples include:
- CIFAR-10
- CIFAR-100
- MNIST
- Custom datasets (requires preprocessing steps defined in the notebook).

---

## Models
- Teacher Model : RESNET-50
- Student Model: RESNET-18

## How It Works

### Conditional GAN (cGAN)
The cGAN framework consists of:
- **Generator:** Synthesizes feature representations conditioned on input class labels.
- **Discriminator:** Distinguishes between real and synthesized feature representations.

### Knowledge Distillation
- **Teacher Model:** Pre-trained on the target dataset, provides ground-truth feature representations.
- **Student Model:** Trained on synthesized features generated by the cGAN.

---

## Results
The results demonstrate the effectiveness of the Virtual Knowledge Distillation framework. Key metrics (e.g., accuracy and model size) are compared between the teacher and student models in the notebook.

---

## Limitations
- The generator, teacher, and student model files are not included in this repository due to file size constraints. Ensure to train these models using the provided code.

---

## References
1. Kim, Sihwan. "A Virtual Knowledge Distillation via Conditional GAN." Big Data & AI Laboratory, Hana Institute of Technology.

---

## Contributing
Contributions are welcome! Please open an issue or submit a pull request for improvements or new features.

---

## License
This project is licensed under the MIT License. See the `LICENSE` file for more details.

---

## Contact
For any questions or issues, please feel free to contact me or open an issue in this repository.
